{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "announced-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog \n",
    "# Version 1.00 28-Jan-2021\n",
    "#\n",
    "# Version 1.0.2 25-Feb-2020\n",
    "# print_prod_CPU.to_csv to print_stg_CPU.head(29).to_csv to only print the 30 PROD servers for CPU util\n",
    "# print_prod_Mem.to_csv to print_stg_Mem.head(29).to_csv to only print the 30 PROD servers for Mem util\n",
    "# print_stg_CPU.to_csv to print_stg_CPU.head(30).to_csv to only print the 30 STG servers for CPU util\n",
    "# print_stg_Mem.to_csv to print_stg_Mem.head(30).to_csv to only print the 30 STG servers for Mem util\n",
    "# Organized the directories\n",
    "# Output file now consolidated in the /weekly_output directory\n",
    "# Added cleanup commands such as removing additional column and resetting the index number in the final output\n",
    "# Combined outputs for prod and staging environments\n",
    "# Combined all .csv outputs to multiple sheets in one .xlsx file\n",
    "# Renamed python script to run-me.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "several-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files needed\n",
    "# 1. envMem.csv - from GoogleSpreadSheet\n",
    "# 2. envCPU.csv - from GoogleSpreadSheet\n",
    "# 3. prodMem.csv - from Splunk (weekly)\n",
    "# 4. prodCPU.csv - from Splunk (weekly)\n",
    "# 5. stgCPU.csv  - from Splunk (weekly)\n",
    "# 6. stgMem.csv - from Splunk (weekly)\n",
    "# 7. prodFS.csv - from Splunk (weekly)\n",
    "# --------------------------------------------------------------------------------\n",
    "# Links:\n",
    "# DPA Environment - https://docs.google.com/spreadsheets/d/1Ll7-mdb8tsGUKIDYJ-dMEBmydxXf24krk8J7r1RIUog/edit#gid=588246582\n",
    "# Splunk (DPA PROD/Staging 2) - http://10.69.81.41:8000/en-US/app/splunk_app_for_linux_Infrastructure/dashboards\n",
    "# --------------------------------------------------------------------------------\n",
    "# Helpful commands\n",
    "#\n",
    "# print(mem_df.loc[[20]]) # printing x row\n",
    "# envMem_df.tail(10)\n",
    "# mem_df.tail(10)\n",
    "# mem_df = df.sort_values(by=['Column_name'], ascending=True) # to sort by column\n",
    "# DPAenv_df.columns # for reference to check which column to join from DPAenv\n",
    "# mergedData.to_csv('filename') # for exporting\n",
    "# mergedData.to_csv('filename', index=False) # to remove the index column\n",
    "# --------------------------------------------------------------------------------\n",
    "# LEGEND:\n",
    "# FS - File System\n",
    "# df - data file (.csv, xlx, etc)\n",
    "# env - environment (official .csv Environment file from google sheets)\n",
    "# --------------------------------------------------------------------------------\n",
    "# How To Use\n",
    "# 1. Rename/save the .csv files to prodMem.csv, stgMem.csv, prodCPU.csv, stgCPU.csv, prodFS.csv\n",
    "# 2. Get Environment files from Google Sheet and name them as envMem.csv, envCPU.csv & envFS.csv\n",
    "# 3. Place them in Jupyter Notebook dir (./DPA_report/sources/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "orange-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "from xlsxwriter import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "theoretical-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmnet files from Google Spreadsheet\n",
    "envMem_df = pd.read_csv('./sources/envMem.csv')\n",
    "envCPU_df = pd.read_csv('./sources/envCPU.csv')\n",
    "envFS_df = pd.read_csv('./sources/envFS.csv')\n",
    "\n",
    "# Weekly data from Splunk\n",
    "prodMem_df = pd.read_csv('./sources/prodMem.csv')\n",
    "stgMem_df = pd.read_csv('./sources/stgMem.csv')\n",
    "prodCPU_df = pd.read_csv('./sources/prodCPU.csv')\n",
    "stgCPU_df = pd.read_csv('./sources/stgCPU.csv')\n",
    "prodFS_df = pd.read_csv('./sources/prodFS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "leading-syracuse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To replace the NaN\n",
    "envMem_df = envMem_df[envMem_df['Host'].isna() == False]\n",
    "envCPU_df = envCPU_df[envCPU_df['Host'].isna() == False]\n",
    "envFS_df = envFS_df[envFS_df['Mount'].isna() == False]\n",
    "\n",
    "prodMem_df = prodMem_df[prodMem_df['Host'].isna() == False]\n",
    "stgMem_df = stgMem_df[stgMem_df['Host'].isna() == False]\n",
    "prodCPU_df = prodCPU_df[prodCPU_df['Host'].isna() == False]\n",
    "stgCPU_df = stgCPU_df[stgCPU_df['Host'].isna() == False]\n",
    "prodFS_df = prodFS_df[prodFS_df['Used'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "experienced-taxation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merging .csv files for Memory usage\n",
    "prod_Mem_mergeData = pd.merge(envMem_df, prodMem_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "stg_Mem_mergeData = pd.merge(envMem_df, stgMem_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "\n",
    "# Merging .csv files for CPU usage\n",
    "prod_CPU_mergeData = pd.merge(envCPU_df, prodCPU_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "stg_CPU_mergeData = pd.merge(envCPU_df, stgCPU_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "\n",
    "# Merging the two .csv files according to 'Host' and 'Mount' via inner join for FS usage (PROD only)\n",
    "prod_FS_mergeData = pd.merge(envFS_df,prodFS_df, left_on=['Host', 'Mount'],right_on=['Host','Mount'], how='inner')\n",
    "#prod_FS_mergeData[['Host', 'Mount', 'Used']].sort_values(['Host', 'Mount']) # uncomment to print to screen / comment to unprint\n",
    "mergeDataPrint = mergeData[['Host', 'Mount', 'Used']].sort_values(['Host', 'Mount']) \n",
    "mergeDataPrint.head(264).to_csv('./raw/prod_FS_Weekly_Output.csv', index = False) \n",
    "#print(mergeDataPrint.head(264))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "public-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables for printing\n",
    "print_prod_Mem = prod_Mem_mergeData[['Host', 'IP Address_x', 'Used']]\n",
    "print_stg_Mem = stg_Mem_mergeData[['Host', 'IP Address_x', 'Used']]\n",
    "print_prod_CPU = prod_CPU_mergeData[['Host', 'IP Address_x', 'Used']]\n",
    "print_stg_CPU = stg_CPU_mergeData[['Host', 'IP Address_x', 'Used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abandoned-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to PRINT TO SCREEN / comment to hide\n",
    "#print_prod_Mem.head(29)\n",
    "#print_stg_Mem.head(30)\n",
    "#print_prod_CPU\n",
    "#print_stg_CPU.head(30)\n",
    "#prodFS_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "reserved-hampton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exporting to .csv for individual utils\n",
    "print_prod_Mem.head(29).to_csv('./raw/prod_Mem_Weekly_Output.csv') # working\n",
    "print_stg_Mem.head(30).to_csv('./raw/stg_Mem_Weekly_Output.csv') # working\n",
    "print_prod_CPU.head(29).to_csv('./raw/prod_CPU_Weekly_Output.csv') # working\n",
    "print_stg_CPU.head(30).to_csv('./raw/stg_CPU_Weekly_Output.csv') # working\n",
    "\n",
    "# PROD & STG MEM - Appending the two .csv output for Mem\n",
    "mem_prod = pd.read_csv('./raw/prod_Mem_Weekly_Output.csv')\n",
    "mem_stg  = pd.read_csv('./raw/stg_Mem_Weekly_Output.csv')\n",
    "mem_weekly = mem_prod.append(mem_stg)# <-- append step\n",
    "mem_weekly = mem_weekly.drop(mem_weekly.columns[[0]], axis=1) # <-- removes additional column created\n",
    "mem_weekly.reset_index(drop=True, inplace=True) # <-- resets the index number\n",
    "mem_weekly.to_csv('./raw/mem_weekly.csv', index = False) # <-- index=False to remove index upon saving\n",
    "#print(mem_weekly)\n",
    "\n",
    "# PROD & STG CPU - Appending the two .csv output\n",
    "prod_CPU = pd.read_csv('./raw/prod_CPU_Weekly_Output.csv')\n",
    "stg_CPU  = pd.read_csv('./raw/stg_CPU_Weekly_Output.csv')\n",
    "CPU_weekly = prod_CPU.append(stg_CPU) # <-- append step\n",
    "CPU_weekly = CPU_weekly.drop(CPU_weekly.columns[[0]], axis=1) # <-- removes additional column created\n",
    "CPU_weekly.reset_index(drop=True, inplace=True) # <-- resets the index number\n",
    "CPU_weekly.to_csv('./raw/CPU_weekly.csv', index = False) # <-- index=False to remove index upon saving\n",
    "#print(CPU_weekly)\n",
    "\n",
    "# Prod FS\n",
    "prod_weekly = pd.read_csv('./raw/prod_FS_Weekly_Output.csv')\n",
    "\n",
    "# Display the number of rows and columns (rows,columns)\n",
    "#mem_weekly.shape\n",
    "#CPU_weekly.shape\n",
    "#prod_weekly.shape\n",
    "\n",
    "# Display the number of rows and columns (rows,columns). Uncomment to view\n",
    "writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
    "CPU_weekly.to_excel(writer, sheet_name = 'CPU', index = False)\n",
    "mem_weekly.to_excel(writer, sheet_name = 'mem', index = False)\n",
    "prod_weekly.to_excel(writer, sheet_name = 'FS', index = False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "irish-meditation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "tribal-agreement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-month",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
