{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "orange-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "from xlsxwriter import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "theoretical-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmnet files from Google Spreadsheet\n",
    "envMem_df = pd.read_csv('./sources/envMem.csv')\n",
    "envCPU_df = pd.read_csv('./sources/envCPU.csv')\n",
    "envFS_df = pd.read_csv('./sources/envFS.csv')\n",
    "\n",
    "# Weekly data from Splunk\n",
    "prodMem_df = pd.read_csv('./sources/prodMem.csv')\n",
    "stgMem_df = pd.read_csv('./sources/stgMem.csv')\n",
    "prodCPU_df = pd.read_csv('./sources/prodCPU.csv')\n",
    "stgCPU_df = pd.read_csv('./sources/stgCPU.csv')\n",
    "prodFS_df = pd.read_csv('./sources/prodFS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "leading-syracuse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To replace the NaN\n",
    "envMem_df = envMem_df[envMem_df['Host'].isna() == False]\n",
    "envCPU_df = envCPU_df[envCPU_df['Host'].isna() == False]\n",
    "#envFS_df = envFS_df[envFS_df['Mount'].isna() == False]\n",
    "\n",
    "prodMem_df = prodMem_df[prodMem_df['Host'].isna() == False]\n",
    "stgMem_df = stgMem_df[stgMem_df['Host'].isna() == False]\n",
    "prodCPU_df = prodCPU_df[prodCPU_df['Host'].isna() == False]\n",
    "stgCPU_df = stgCPU_df[stgCPU_df['Host'].isna() == False]\n",
    "prodFS_df = prodFS_df[prodFS_df['Used'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "experienced-taxation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Host                Mount  Used\n",
      "0                                        dpaanalytics                    /  15.0\n",
      "1                                        dpaanalytics          /appl/depot   1.0\n",
      "2                                        dpaanalytics  /appl/di_shareddata   1.0\n",
      "3                                        dpaanalytics      /appl/sasbackup   1.0\n",
      "4                                        dpaanalytics        /appl/sasdata   1.0\n",
      "..                                                ...                  ...   ...\n",
      "250  ip-10-237-82-146.ap-southeast-1.compute.internal      /appl/sasbackup   1.0\n",
      "251  ip-10-237-82-146.ap-southeast-1.compute.internal        /appl/sashome   4.0\n",
      "252  ip-10-237-82-146.ap-southeast-1.compute.internal        /appl/saslogs   1.0\n",
      "253  ip-10-237-82-146.ap-southeast-1.compute.internal                 /dev   0.0\n",
      "254  ip-10-237-82-146.ap-southeast-1.compute.internal                /work  46.0\n",
      "\n",
      "[255 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merging .csv files for Memory usage\n",
    "prod_Mem_mergeData = pd.merge(envMem_df, prodMem_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "stg_Mem_mergeData = pd.merge(envMem_df, stgMem_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "\n",
    "# Merging .csv files for CPU usage\n",
    "prod_CPU_mergeData = pd.merge(envCPU_df, prodCPU_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "stg_CPU_mergeData = pd.merge(envCPU_df, stgCPU_df, left_on='Host', right_on='Host', how='right').sort_values('IP Address_x')\n",
    "\n",
    "# Merging the two .csv files according to 'Host' and 'Mount' via inner join for FS usage (PROD only)\n",
    "prod_FS_mergeData = pd.merge(envFS_df,prodFS_df, left_on=['Host', 'Mount'],right_on=['Host','Mount'], how='inner')\n",
    "#prod_FS_mergeData[['Host', 'Mount', 'Used']].sort_values(['Host', 'Mount']) # uncomment to print to screen / comment to unprint\n",
    "mergeDataPrint = prod_FS_mergeData[['Host', 'Mount', 'Used']].sort_values(['Host', 'Mount']) \n",
    "mergeDataPrint.head(264).to_csv('./raw/prod_FS_Weekly_Output.csv', index = False) \n",
    "print(mergeDataPrint.head(264))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "public-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables for printing\n",
    "print_prod_Mem = prod_Mem_mergeData[['Host', 'IP Address_x', 'Used']]\n",
    "print_stg_Mem = stg_Mem_mergeData[['Host', 'IP Address_x', 'Used']]\n",
    "print_prod_CPU = prod_CPU_mergeData[['Host', 'IP Address_x', 'Used']]\n",
    "print_stg_CPU = stg_CPU_mergeData[['Host', 'IP Address_x', 'Used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abandoned-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to PRINT TO SCREEN / comment to hide\n",
    "#print_prod_Mem.head(29)\n",
    "#print_stg_Mem.head(30)\n",
    "#print_prod_CPU\n",
    "#print_stg_CPU.head(30)\n",
    "#prodFS_df.head(10)\n",
    "#prodFS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reserved-hampton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exporting to .csv for individual utils\n",
    "print_prod_Mem.head(29).to_csv('./raw/prod_Mem_Weekly_Output.csv') # working\n",
    "print_stg_Mem.head(30).to_csv('./raw/stg_Mem_Weekly_Output.csv') # working\n",
    "print_prod_CPU.head(29).to_csv('./raw/prod_CPU_Weekly_Output.csv') # working\n",
    "print_stg_CPU.head(30).to_csv('./raw/stg_CPU_Weekly_Output.csv') # working\n",
    "\n",
    "# PROD & STG MEM - Appending the two .csv output for Mem\n",
    "mem_prod = pd.read_csv('./raw/prod_Mem_Weekly_Output.csv')\n",
    "mem_stg  = pd.read_csv('./raw/stg_Mem_Weekly_Output.csv')\n",
    "mem_weekly = mem_prod.append(mem_stg)# <-- append step\n",
    "mem_weekly = mem_weekly.drop(mem_weekly.columns[[0]], axis=1) # <-- removes additional column created\n",
    "mem_weekly.reset_index(drop=True, inplace=True) # <-- resets the index number\n",
    "mem_weekly.to_csv('./raw/mem_weekly.csv', index = False) # <-- index=False to remove index upon saving\n",
    "#print(mem_weekly)\n",
    "\n",
    "# PROD & STG CPU - Appending the two .csv output\n",
    "prod_CPU = pd.read_csv('./raw/prod_CPU_Weekly_Output.csv')\n",
    "stg_CPU  = pd.read_csv('./raw/stg_CPU_Weekly_Output.csv')\n",
    "CPU_weekly = prod_CPU.append(stg_CPU) # <-- append step\n",
    "CPU_weekly = CPU_weekly.drop(CPU_weekly.columns[[0]], axis=1) # <-- removes additional column created\n",
    "CPU_weekly.reset_index(drop=True, inplace=True) # <-- resets the index number\n",
    "CPU_weekly.to_csv('./raw/CPU_weekly.csv', index = False) # <-- index=False to remove index upon saving\n",
    "#print(CPU_weekly)\n",
    "\n",
    "# Prod FS\n",
    "prod_weekly = pd.read_csv('./raw/prod_FS_Weekly_Output.csv')\n",
    "\n",
    "# Display the number of rows and columns (rows,columns)\n",
    "#mem_weekly.shape\n",
    "#CPU_weekly.shape\n",
    "#prod_weekly.shape\n",
    "\n",
    "# Display the number of rows and columns (rows,columns). Uncomment to view\n",
    "writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
    "CPU_weekly.to_excel(writer, sheet_name = 'CPU', index = False)\n",
    "mem_weekly.to_excel(writer, sheet_name = 'mem', index = False)\n",
    "prod_weekly.to_excel(writer, sheet_name = 'FS', index = False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
